# W1

## 0710 리뷰/회고

## day4 리뷰

W1M3 complete

W1M3 하는 과정 속에서 고민했던 것들

- 자동화된 스크립트를 작성할 것 -> main 함수가 자동적으로 계속해서 실행하면서 최신의 GDP를 출력하는지 아니면 ETL 프로세스를 자동으로 처리되게 하는지 ? 자동화의 기준이 모호하였음
  - 내가 내린 결론 : ETL 프로세스를 자동으로 하는 것은 당연한 것 같고 함수를 주기적으로 실행만 해주면 전자의 조건도 맞춘다고 생각하여 계속해서 실행을 해도 쓸모없는 데이터를 유지하지 않고 최신의 데이터를 유지할 수 있도록 설계

- IMF에서 매년 2회 이 자료를 제공하기 때문에 정보가 갱신되더라도 해당 코드를 재사용해서 정보를 얻을 수 있어야 합니다 -> IMF에서 제공하는 자료가 Wiki에 갱신되고 같은 table에 되기 떄문에 크롤링에 문제는 없어보임 
  - 내가 내린 결론 : 다만 내가 생각지도 못한 이유가 더 있을 수 있으므로 좀더 생각해볼 것

- 각 Region별로 top5 국가의 GDP 평균을 구해서 화면에 출력해야 합니다 -> wiki 에서 제공하는 region은 9개 정도로 다양하고 한 국가가 여러 region에 속하는 경우가 있었음
  - 내가 내린 결론 : region을 통해서 결과를 보고싶다는 것은 같이 모여있는 국가들에 대해서 사업을 하고 싶다고 생각했음. 그렇기에 흔히 5대양 6대주로 말하는 대륙으로 region을 나누었고
  - 이 중에서도 중복이 존재하지만 하나의 region에만 속하지 않고 여러 Region에 속하도록 하였음

- ETL 프로세스를 설계함에 있어서 인자들을 넘겨주어야 할까?
  - 내가 내린 결론 : Dano가 각각 다른사람이 설계한다고 생각하라고 했기에 넘겨주는 인자없이 독립적으로 실행될 수 있도록 함수 정의
  - 이렇게 한다면 E 에서 T로 넘어가는 부분은 json 으로 넘겨주는데 T 에서 L에 넘어가는 부분이 애매해졌음
  - 그래서 처음에는 csv로 저장하여 Load 로 넘기는 것으로 하였는데 팀 활동을 통해서 얘기하였고
  - parquet 이라는 자료형을 알게 되었고 parquet은 칼럼단위로 압축하기에 압축률이 좋다는 것을 알게 되었음
 
- wikipeida 페이지가 아닌, IMF 홈페이지에서 직접 데이터를 가져오는 방법은 없을까요? 어떻게 하면 될까요? -> IMF 홈페이지에 엑셀 형식으로 제공하기 때문에 이를 동적으로 다운받아 다룰수 있는 셀레니움으로 크롤링을 해야할 듯
  - 내가 내린 결론 : 셀레니움으로도 W1M3 해보자

- 만약 데이터가 갱신되면 과거의 데이터는 어떻게 되어야 할까요? 과거의 데이터를 조회하는 게 필요하다면 ETL 프로세스를 어떻게 변경해야 할까요?
  - 내가 내린 결론 : 기존의 테이블에 데이터가 갱신되었을 때 추가해야한다고 생각함
  - 하지만 갱신이 안되었을 때도 데이터가 추가되면 더미 데이터가 되므로, 앞서 GDP 데이터에 html에서 제공하는 last modfied date 를 참고하여 update_date 필드를 추가 해줌으로써
  - update_date 가 다를때만 추가하도록 함으로써 과거 데이터 유지하면서 갱신 데이터 추가


## day4 회고

### Keep
미션을 수행함에 있어서 내가 어떤 생각으로 어떤 행동을 했는지 팀원들에게 말하고 그것에 대한 피드백을 받으면서 새로운 개념에 대해서도 알게되고 같은 미션에 대해서도 다른 시각을 경험할 수 있음

### Problem


### Try
GPT를 통해서 핵심 method 들을 정리한 후 method 의 예시는 공식 문서를 통해 확인하고 적용하기
