# W3

## 0725 리뷰/회고

## day15 리뷰

### 개인활동

EMERGENCY!!!!!! 미션 꼭 하자 주어진 임무니까..

나만의 하둡 정리

Hadoop cluster 를 구성을 할 때에는 Master node 와 Worker node들로 구성을 한다
Master node 에서는 NameNode, SecondaryNameNode, ResourceManager 가 실행되고 Worker node 에서는 DataNode, NodeManager 가 실행된다

hadoop 은 hdfs라는 Storage Layer가 존재하고 이를 Yarn 을 통해서 Management 한다

hdfs의 구성인 Namenode 는 hadoop 머리라고 생각하면되고 없으면 안된다.

Master Node에 위치하고 어떻게 보면 Namenode가 존재하는 곳이 Master Node야 라고 말해주는 것 같기도 하다. 

hadoop cluster 의 메타 데이터를 관리하고 이를 잃게된다면 DataNode의 데이터를 사용하지 못하기에 SecondaryNameNode를 두어 손상이 되더라도 대처가 가능하다.

DataNode는 실질적인 데이터를 저장하는 Node이고 WorkerNode안에 존재한다. 

MasterNode의 Workers를 통해 WorkerNode를 식별한 뒤 DataNode를 생성하고 실행한다. 

이제는 Yarn의 구성인 ReousrceManager는 MasterNode에 위치하고 내부적으로 Scheduler와 ApplicationManager를 가지고 있다. 

이를 통해서 MapReduce와 같은 application이 실행되어야 할때 어떤 WorkerNode에 이를 실행시킬지와 같은 결정을 위해 ResourceManager가 관여한다. 

그리고 NodeManager는 WorkerNode에 존재하고 DataNode에 대한 정보 또는 WorkerNode의 내부 메모리 등을 알고있어

application을 실행시키기 위한 조건이 되는지 확인해주는 역할을 한다.

이렇게 각자 노드들의 역할을 나누어져 있고 인터페이스를 사용하여 내부에서 어떤 일을 하는지 알 필요없이 각자의 신호들만을 통해서 소통한다. 

Master와 Worker 그리고 각 노드들의 개념을 이용해서 distributed 하게 데이터를 저장하고 이를 처리해야할 것이다. 이때 MapReduce라는 Software Framework를 통해 parallel하게 처리한다. 이떄 Mapper는 data를 split 단위로 나눈 것을 key,value 타입으로 mapping 하고 Local에 저장하는 역할을 한다. 이후 sort & shuffle 과정이 이루어 지고 reducer 는 데이터를 요약한다. 여기서 mapping이 local에서 일어나고 저장하는데 이는 data computation is cheaper than moving data라는 hadoop의 기본원칙에서 나온 결과이다.

팀 활동할때 데이터 analysis 와 같은 것은 내가 아닌 다른 사람이 한다고 생각하고 나는 거기에 필요한 data를 feed 를 목적으로 한다

하지만 그것을 진행함에 있어서 비즈니스적 생각이 없으면 안됨

## day15 회고

### Keep

### Problem
주어진 임무를 다하지 못했음에도 더 좋은 공부법이나 시간 활용법을 생각해내지 못한것
-> 학습 방법의 문제도 있지만 못해도 아무렇지 않은 정신상태가 문제임 (정신차리셈)
-> 미션을 끝낼 날을 정해놓고 그 날에 어떻게 해서든 끝낼 수 있도록 나와의 약속을 할 것..... 

### Try
