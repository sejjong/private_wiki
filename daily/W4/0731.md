# W4

## 0731 리뷰/회고

## day19 리뷰
### 개인활동
W4M3
인상적인 내용
- cpu, memory 와 같은 하드웨어의 성능이 발전하고 크롤링에 사용되는 소프트웨어도 발전함에 따라 당연하게 크롤링의 성능이 증가할 것 같았음.
- 하지만 이들의 발전과 같이 웹 또한 HTML 에서 javascript로 넘어가고, 담고있는 컨텐츠도 무거워져 크롤링의 어느정도의 한계가 있다는 것이 인상적임. 
- 또한 앞서 미션으로 크롤링을 했을 때 거의 동적이었는데 아직도 HTML만으로도 크롤링할 데이터가 많다는 것도 인상적임.

아키텍처
- 본문의 아키텍처는 모든 기능을 단일 노드에 통합하고 있고 각 노드는 Fetcher, redis instance, parser로 구성된 구조를 가지고 있음그렇기에 수평 확장이 가능한 구조임.
- 전체 클러스터는 노드 간 통신 없이 시드 도메인을 샤딩해서 중복 없는 범위만 담당하기 때문에 단일 노드만으로 실험과 확장이 가능하고 노드 간 의존성이 없기에 Fault-tolerance에도 용이하다. 
- 일반적으로 각 요소들을 다른 노드로 구성한 클러스터 구조가 아닌 하나의 노드가 작은 클러스터를 구성하는 것 처럼 구조가 프로토타이핑을 구현하기에 적합하다고 생각함

어떤 의사결정이 놀라웠나요?
- 단일 노드의 수직적인 확장을 최대화 하기 위해 fetcher, parser의 각 요소들의 특성에 따라 비율을 다르게 한 것이 놀라웠음.
- fetcher에서는 network 보다 cpu에서 병목이 발생한다는 것을 파악하고, 
- parser에서는 cpu bound 작업이기에 병렬로 워커노드를 늘리는 것 보다 CPU를 포화시키는 적절한 수를 맞춘게 엔지니어스럽다(나도 저래야할텐데) 라는 생각이 들었음.

소감 : 

크롤링이란게 단순해 보이지만 이를 하는데 필요한 클러스터를 구성하는데에도 들어가는 지식이 생각보다 많다, 

데이터 엔지니어로서 크롤링은 기본인 것 같아서 미션에서 한 것 뿐만 아닌 혼자서 하나의 문제를 세우고 풀기위한 크롤링을 해봐야겠다.

음.. 데이터를 만지면서 데이터를 다루는 툴을 배우면서, 우리가 쉽게 볼 수 있는 데이터들(actionable data)은 많은 사람들의 노력이 들어간 결과라는 것을 몸소 느끼고 있는 것 같다.

### 팀활동

## day19 회고

### Keep

### Problem
미션을 수행함에 있어서 데이터가 정해져 있지 않기 떄문에 나의 선택인데 코드의 복잡성을 줄이기 위해 작은 데이터를 선택하여 수행하면서 spark의 사용의 이유를 느끼지 못했음

=> 다음 미션에 있어서 미션을 수행하는 이유(이번에는 spark의 신속성?)를 충족할만큼 충분한 데이터나, 툴을 사용하자 / 주말에 더 많은 택시 데이터로 스파크의 스피드를 느껴보자!
### Try
