# W4

## 0728 리뷰/회고

## day16 리뷰

### 개인활동
hadoop 에 비해 spark 는 조금 더 유연한 느낌이 든다

hadoop의 master/worker안에는 각 namenode, datanode와 같이 필수적으로 들어가야하는 노드들이 있고

각 master/worker는 하나의 machine(docker container)라는 느낌이 있다

그에비해 spark는 JVM 자체가 master 이고 worker 이다

master안에 JVM node들이 종속되는 것이 아닌 master/worker 그 자체가 JVM이라는게 조금 낯설다

지금은 standalone cluster로 하나의 docker container 안에서 master worker JVM을 띄우고 있는데 hdfs는 사용가능 하지 않다

분명 hadoop 포함된 spark를 install한 것 같은데 Dano가 마지막에 말해준게 이것과 관련이 있는 것 같다.

hadoop때도 그랬지만 이번에도 혼자 고심해가면서 spark의 동작과정을 그림 그려가며 이해해 나갔다

이해도가 많이 높아진 것 같지만 아직 pdf를 보면 아리송한게 몇개 있다 더 파고들어가며 질문하는 시간이 필요한 것 같다.

spark의 in-memory 방식이 처음에는 이해가 안갔었다

하드에 저장하는 것이 아닌 memory(ram)에 저장하고 사용하여 하드에 비해 속도가 빠른 것은 알겠다 (정확히 이런 방식 맞겠지?)

근데 hadoop 개발 당시에는 ram을 사용할 생각을 못했을까 ? 그 사람들도 하드보다 ram이 빠른건 당연히 알텐데..

그러다가 그 당시를 생각해보니 2000년 초반 ram의 가격은 엄청 비싸고 용량자체도 크지 않았기 때문에 그들에게는 당연하게도 하드를 사용한 것으로 보인다

그리고 2010이 되면서 ram의 가격이 싸지고 용량도 늘게 되며 ram을 사용하는 in-memory 방식을 사용하게 된 것 같다

하지만 이 경우에도 ram이 무한하지 않기에 job처리 과정에서 OOM 문제가 생길 수 있을텐데 이때는 하드에 저장하는 처리방식이 존재한다.

역사를 생각해보니 처리방식에 대해 이해하는데 도움이 되었다 -> 근데 사실 정확히 이런 이유로 ram을 사용안하다 한지는 모름..

Dano의 배려로 standalone cluster 방식으로 하지만 spark의 더 높은 이해력을 위해서 혼자서 yarn환경에서도 cluster가 잘 동작하도록 구현해봐야겠다.
## day16 회고

### Keep
새로운 개념을 배울 때 그림을 그려가며 전체적인 흐름을 이해하고, 누군가에게 설명할 수 있을만큼 학습하는 것

### Problem

### Try
